{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn stock",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+JN33/Lymci86yT25QmXA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedElgabryi/StockRNN/blob/master/rnn_stock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DypqgFzeSekI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.models import load_model\n",
        "from err import error_count, calc_diff\n",
        "from visual import plot\n",
        "\n",
        "############ Data Preprocessing ############\n",
        "# Importing Training Set\n",
        "ds = pd.read_csv('TICKER.csv')\n",
        "dataset = ds.iloc[:, [2,5]].values\n",
        "\n",
        "X = ds.iloc[:, 2].values\n",
        "y = ds.iloc[:, 5].values\n",
        "\n",
        "# Feature Scaling\n",
        "scaler  = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset_scaled = scaler.fit_transform(dataset)\n",
        "\n",
        "X = dataset_scaled[:, 0]\n",
        "y = dataset_scaled[:, 1]\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# Sizes of dataset, train_ds, test_ds\n",
        "dataset_sz = X.shape[0]\n",
        "train_sz = X_train.shape[0]\n",
        "test_sz = X_test.shape[0]\n",
        " \n",
        "# reshape our data into 3 dimensions, [batch_size, timesteps, input_dim]\n",
        "X_train = np.reshape(X_train, (train_sz, 1, 1))\n",
        "y_train = np.reshape(y_train, (train_sz, 1))\n",
        "\n",
        "############ Building the RNN ############\n",
        "# Initializing the RNN\n",
        "regressor = Sequential()\n",
        " \n",
        "# Adding fist LSTM layer and Drop out Regularization\n",
        "regressor.add(LSTM(units=500, return_sequences=True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(.2))\n",
        " \n",
        "# Adding 2nd layer with some drop out regularization\n",
        "regressor.add(LSTM(units=500, return_sequences=True))\n",
        "regressor.add(Dropout(.2))\n",
        " \n",
        "# Adding 3rd layer with some drop out regularization\n",
        "regressor.add(LSTM(units=500, return_sequences=True))\n",
        "regressor.add(Dropout(.2))\n",
        " \n",
        "# Adding 4th layer with some drop out regularization\n",
        "regressor.add(LSTM(units=500, return_sequences=False))\n",
        "regressor.add(Dropout(.2))\n",
        " \n",
        "# Output layer\n",
        "regressor.add(Dense(units=1, activation='sigmoid'))\n",
        " \n",
        "# Compiling the RNN\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "# Train :)\n",
        "history = regressor.fit(X_train, y_train, epochs=200, batch_size=32)\n",
        "\n",
        "############ Save & load Trained Model ############\n",
        "# Save Trained Model\n",
        "regressor.save('TICKER-RNN.h5')\n",
        "\n",
        "# deletes the existing model\n",
        "del regressor\n",
        "\n",
        "# load Trained Model\n",
        "regressor = load_model('TICKER-RNN.h5')\n",
        "\n",
        "############ Predict & Test the Model ############\n",
        "real_stock_price = np.array(X_test)\n",
        "inputs = real_stock_price\n",
        "inputs = np.reshape(inputs, (test_sz, 1, 1))\n",
        "predicted_stock_price = regressor.predict(inputs)\n",
        "\n",
        "# rebuild the Structure\n",
        "dataset_test_total = pd.DataFrame()\n",
        "dataset_test_total['real'] = real_stock_price\n",
        "dataset_test_total['predicted'] = predicted_stock_price\n",
        "\n",
        "# real data price VS. predicted price\n",
        "predicted_stock_price = scaler.inverse_transform(dataset_test_total) \n",
        "\n",
        "# count of Wrong predicted value after applying treshold\n",
        "err_cnt = error_count(predicted_stock_price[:, 0], predicted_stock_price[:, 1], toler_treshold = 5.0)\n",
        "\n",
        "# Calc difference between real data price and predicted price\n",
        "diff_rate = calc_diff(predicted_stock_price[:, 0], predicted_stock_price[:, 1])\n",
        "\n",
        "# MSE\n",
        "mse = mean_squared_error(predicted_stock_price[:, 0], predicted_stock_price[:, 1])\n",
        "\n",
        "############ Visualizing the results ############\n",
        "inputs = np.array(X)\n",
        "inputs = np.reshape(inputs, (dataset_sz, 1, 1))\n",
        "\n",
        "all_real_price = np.array(y)\n",
        "all_predicted_price = regressor.predict(inputs)\n",
        "\n",
        "# rebuild the Structure\n",
        "dataset_pred_real = pd.DataFrame()\n",
        "dataset_pred_real['real'] = all_real_price\n",
        "dataset_pred_real['predicted'] = all_predicted_price\n",
        "\n",
        "# real test data price VS. predicted price\n",
        "all_prices = scaler.inverse_transform(dataset_pred_real)\n",
        "\n",
        "## Visualising the results\n",
        "plot(predicted=all_prices[:, 0])\n",
        "plot(real=all_prices[:, 1])\n",
        "plot(predicted=all_prices[:, 0], real=all_prices[:, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORQlp3T4ZF5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}